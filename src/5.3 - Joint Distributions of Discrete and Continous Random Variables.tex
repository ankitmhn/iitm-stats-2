\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{geometry}
\usepackage{graphicx}

\geometry{margin=1in}

\title{Lecture Summary: Joint Distributions of Discrete and Continuous Random Variables}
\author{}
\date{}

\begin{document}

\maketitle

\section*{Source: Lecture 5.2.docx}

\section*{Key Points}

\begin{itemize}
  \item \textbf{Introduction to Joint Distributions:}
    \begin{itemize}
      \item Describes relationships between two random variables where one is discrete, and the other is continuous.
      \item Joint distributions model dependencies in real-world datasets, such as the Iris dataset (class as discrete, sepal length as continuous).
    \end{itemize}

  \item \textbf{Notation and Conditional Densities:}
    \begin{itemize}
      \item For discrete random variable $X$ with PMF $p_X(x)$, the conditional density of $Y$ given $X=x$ is denoted:
        \[
          f_{Y|X}(y|x).
        \]
      \item Marginal density of $Y$ is obtained using the total probability law:
        \[
          f_Y(y) = \sum_{x} p_X(x) f_{Y|X}(y|x).
        \]
    \end{itemize}

  \item \textbf{Gaussian Mixtures:}
    \begin{itemize}
      \item Conditional densities can form a mixture distribution.
      \item Example:
        \begin{itemize}
          \item $X$ is uniform over $\{0, 1, 2\}$.
          \item $Y|X=0 \sim N(5, 0.4)$, $Y|X=1 \sim N(6, 0.5)$, $Y|X=2 \sim N(7, 0.6)$.
          \item Marginal $f_Y(y)$ is a Gaussian mixture:
            \[
              f_Y(y) = \frac{1}{3}\left(f_{N(5,0.4)}(y) + f_{N(6,0.5)}(y) + f_{N(7,0.6)}(y)\right).
            \]
        \end{itemize}
    \end{itemize}

  \item \textbf{Reverse Problems and Bayes-like Rule:}
    \begin{itemize}
      \item Conditional probability of the discrete variable given the continuous variable:
        \[
          P(X=x|Y=y) = \frac{p_X(x)f_{Y|X}(y|x)}{f_Y(y)}.
        \]
      \item Analogous to Bayesâ€™ theorem, replacing probabilities with densities for continuous variables.
      \item Example:
        \begin{itemize}
          \item $X \in \{-1, 1\}$, $P(X=-1) = P(X=1) = 0.5$.
          \item $Y|X=-1 \sim \text{Uniform}(-2, 2)$, $Y|X=1 \sim \text{Exp}(5)$.
          \item Marginal $f_Y(y)$ combines these densities, and $P(X=x|Y=y)$ is computed using the formula.
        \end{itemize}
    \end{itemize}

  \item \textbf{Applications and Practical Examples:}
    \begin{itemize}
      \item Classification:
        \begin{itemize}
          \item Observing a continuous value $Y$ to predict the discrete class $X$.
          \item Example: Height and gender prediction using height distribution for males and females.
        \end{itemize}
      \item Communication systems: Modeling signal distributions with discrete states and continuous noise.
    \end{itemize}
\end{itemize}

\section*{Simplified Explanation}

\textbf{Joint Distributions:}
Combines discrete and continuous random variables:
- $X$: Discrete, with PMF $p_X(x)$.
- $Y$: Continuous, with conditional density $f_{Y|X}(y|x)$.

\textbf{Key Formula:}
Marginal density of $Y$:
\[
  f_Y(y) = \sum_{x} p_X(x) f_{Y|X}(y|x).
\]

\textbf{Reverse Problem:}
Find $P(X=x|Y=y)$:
\[
  P(X=x|Y=y) = \frac{p_X(x)f_{Y|X}(y|x)}{f_Y(y)}.
\]

\textbf{Example:}
Height of individuals in a population:
- Male heights: $N(160, 10^2)$.
- Female heights: $N(150, 5^2)$.
- Observing a height of 155 cm, predict the gender using the conditional probabilities.

\section*{Conclusion}

In this lecture, we:
\begin{itemize}
  \item Introduced joint distributions of discrete and continuous random variables.
  \item Discussed Gaussian mixtures and Bayes-like rules for reverse problems.
  \item Highlighted applications in classification and modeling.
\end{itemize}

These concepts are foundational in probability and statistics, offering tools for analyzing mixed-variable datasets.

\end{document}
